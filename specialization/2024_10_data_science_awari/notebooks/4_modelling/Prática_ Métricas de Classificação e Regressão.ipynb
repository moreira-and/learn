{"cells":[{"cell_type":"markdown","source":["![header-notebooks.png](data:image/png;base64,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)\n","\n","Pr√°tica da **Aula 15: Machine Learning V**, do curso de **Data Science** da **[Awari](https://awari.com.br/)**. Para utiliz√°-la, v√° no menu \"Arquivo\" e, em seguida, na op√ß√£o \"Salvar uma c√≥pia no Drive\". Isto criar√° uma c√≥pia deste notebook em uma pasta chamada \"Colab Notebooks\", no seu Google Drive pessoal. Use a c√≥pia para criar novas c√©lulas de c√≥digo ou executar as c√©lulas desta pr√°tica.\n","\n","---"],"metadata":{"id":"4E6QJ02t86FD"}},{"cell_type":"markdown","source":["# **M√©tricas de Classifica√ß√£o e Regress√£o**"],"metadata":{"id":"TBUQuyk2j415"}},{"cell_type":"markdown","metadata":{"id":"7x5LXjyF5nc7"},"source":["## **Objetivo**\n","\n","Nesta pr√°tica, iremos comentar e demonstrar algumas m√©tricas para modelos de Classifica√ß√£o e Regress√£o.\n","\n","Ap√≥s o processo de *feature engineering* (engenharia de recursos ou \"ajuste das vari√°veis\"), de implementarmos um modelo e obtermos sa√≠das em forma de probabilidades ou classe, a pr√≥xima necessidade √© entender o qu√£o eficaz o modelo √©, baseado em alguma m√©trica.\n","\n","√â importante conhecer m√©tricas e saber como us√°-las para saber se os resultados entregues pelo modelo est√£o sendo satisfat√≥rios ou n√£o.\n","\n","Esta p√°gina do [Scikit-learn](https://scikit-learn.org/stable/modules/model_evaluation.html) fornece uma boa refer√™ncia sobre o assunto."]},{"cell_type":"markdown","source":["## **Pr√°tica**"],"metadata":{"id":"LPFFvzpqk1A0"}},{"cell_type":"markdown","source":["### **Vis√£o geral**\n","\n","**M√©tricas de Classifica√ß√£o:**\n","\n","- Accuracy.\n","- Logarithmic Loss.\n","- ROC, AUC.\n","- Confusion Matrix.\n","- Classification Report.\n","\n","**M√©tricas de Regress√£o:**\n","\n","- Mean Absolute Error. MAE\n","- Mean Squared Error. MSE\n","- Root Mean Squared Error. RMSE\n","- Root Mean Squared Logarithmic Error. RMSLE\n","- R Square.\n","- Adjusted R Square.\n","\n","Em **problemas de classifica√ß√£o**, usamos dois tipos de algoritmos (dependendo do tipo de sa√≠da que ele cria):\n","\n","- **Sa√≠da de classe**: Algoritmos como SVM e KNN criam uma sa√≠da de classe. Por exemplo, em um problema de classifica√ß√£o bin√°ria, as sa√≠das ser√£o 0 ou 1. Os algoritmos do SKLearn/Outros podem converter essas sa√≠das de classe em probabilidade.\n","\n","- **Sa√≠da de probabilidade**: Algoritmos como Regress√£o Log√≠stica, Floresta Aleat√≥ria, Aumento de Gradiente, Adaboost etc. fornecem sa√≠das de probabilidade. As sa√≠das de probabilidade podem ser convertidas em sa√≠das de classe criando uma probabilidade limite.\n","\n","Em **problemas de regress√£o**, a sa√≠da √© sempre cont√≠nua por natureza e n√£o requer tratamento adicional."],"metadata":{"id":"jrDKRjU5k4Ah"}},{"cell_type":"markdown","metadata":{"id":"Lfc9ouiK5nc9"},"source":["### **M√©tricas de Classifica√ß√£o**\n","\n","Vamos usar o dataset [diabetes.csv](diabetes.csv) referente a dados deste tipo de doen√ßa para nossa pr√°tica. Fa√ßa upload do mesmo para o seu Google Drive, para poder import√°-lo a seguir.\n","\n","A avalia√ß√£o ser√° feita por `Logistic Regression`, `SGDClassifier` e `RandomForestClassifier`."]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"id":"G1imlwzSBhE8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn import metrics\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression, SGDClassifier\n","from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, StratifiedKFold\n","\n","import matplotlib.pyplot as plt\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"6tL29fXpdeWi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["diabetes_data = pd.read_csv('/content/drive/MyDrive/diabetes.csv')\n","\n","X =  diabetes_data.drop([\"Outcome\"],axis = 1)\n","y = diabetes_data[\"Outcome\"]"],"metadata":{"id":"-AcdxhuYdn5N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["diabetes_data.shape"],"metadata":{"id":"Vq4ciL8y6WHn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["diabetes_data.head()"],"metadata":{"id":"Se54VnrS6hHh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Treinando v√°rios modelos com v√°rios hiperpar√¢metros usando o conjunto de treinamento, selecione o modelo e os hiperpar√¢metros que apresentam melhor desempenho no conjunto de valida√ß√£o.\n","# Uma vez que o tipo de modelo e os hiperpar√¢metros tenham sido selecionados, treinamos o modelo final usando esses hiperpar√¢metros no conjunto de treinamento completo, o erro generalizado √© finalmente medido no conjunto de teste.\n","X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = 56)\n"],"metadata":{"id":"tIeIpwTGdqRS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# StratifiedKFold class realiza amostragem estratificada para produzir dobras\"folds\" que cont√™m uma propor√ß√£o representativa de cada classe.\n","cv = StratifiedKFold(n_splits=10, shuffle = True, random_state = 76)"],"metadata":{"id":"u70tbNGzdvs8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Treinando diversos modelos"],"metadata":{"id":"rVt0y6FAemTT"}},{"cell_type":"code","source":["# Logistic Regression - Regress√£o Log√≠stica\n","clf_logreg = LogisticRegression()\n","# fit model - treino do modelo\n","clf_logreg.fit(X_train, y_train)\n","# Previs√µes de classe para o conjunto de valida√ß√£o.\n","y_pred_class_logreg = cross_val_predict(clf_logreg, X_train, y_train, cv = cv)\n","# probabilidades previstas para a classe 1, probabilidades da classe positiva\n","y_pred_prob_logreg = cross_val_predict(clf_logreg, X_train, y_train, cv = cv, method=\"predict_proba\")\n","y_pred_prob_logreg_class1 = y_pred_prob_logreg[:, 1]\n"],"metadata":{"id":"FQtYOK6wdy9y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Random Forest Classifier\n","clf_rfc = RandomForestClassifier()\n","# fit model - treino\n","clf_rfc.fit(X_train, y_train)\n","# Previs√µes de classe para o conjunto de valida√ß√£o.\n","y_pred_class_rfc = cross_val_predict(clf_rfc, X_train, y_train, cv = cv)\n","# probabilidades previstas para a classe 1\n","y_pred_prob_rfc = cross_val_predict(clf_rfc, X_train, y_train, cv = cv, method=\"predict_proba\")\n","y_pred_prob_rfc_class1 = y_pred_prob_rfc[:, 1]"],"metadata":{"id":"ao_ygHrZd2Yj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SGD Classifier\n","clf_SGD = SGDClassifier()\n","# fit model - treino\n","clf_SGD.fit(X_train, y_train)\n","# Previs√µes de classe para o conjunto de valida√ß√£o.\n","y_pred_class_SGD = cross_val_predict(clf_SGD, X_train, y_train, cv = cv)\n","# probabilidades previstas para a classe 1\n","y_pred_prob_SGD = cross_val_predict(clf_SGD, X_train, y_train, cv = cv, method=\"decision_function\")"],"metadata":{"id":"uN8zajFRdkwb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uuG0JKIl5nc_"},"source":["**Nota r√°pida**: `predict_log_proba` do Scikit-Learn d√° o logaritmo das probabilidades. Isso √© mais pr√°tico porque as probabilidades podem tornar-se muito, muito pequenas."]},{"cell_type":"markdown","source":["#### **Acur√°cia nula**\n","\n","- Precis√£o que poderia ser alcan√ßada prevendo sempre a classe mais frequente.\n","- Isso significa que um modelo \"burro\" que sempre prev√™ 0/1 estaria certo \"null_accuracy\" % das vezes."],"metadata":{"id":"jlwO9Yo_qFSa"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_j9b1F9h5nc_"},"outputs":[],"source":["from sklearn.base import BaseEstimator\n","import numpy as np\n","\n","class BaseClassifier(BaseEstimator):\n","    def fit(self, X, y=None):\n","        pass\n","    def predict(self, X):\n","        return np.zeros((len(X), 1), dtype=bool)\n","\n","base_clf = BaseClassifier()\n","cross_val_score(base_clf, X_train, y_train, cv=10, scoring=\"accuracy\").mean()\n"]},{"cell_type":"markdown","metadata":{"id":"nXkxaYu75ndB"},"source":["#### **Classification Accuracy** ou **Acur√°cia**\n","\n","*Classification Accuracy* ou Acur√°cia √© a raz√£o entre o n√∫mero de previs√µes corretas e o n√∫mero total de amostras de entrada.\n","\n","$$Accuracy = \\frac{Number\\ of\\ correct\\ predictions}{Total\\ number\\ of\\ predictions\\ made} = \\frac{TP + TN}{TP + TN + FP + FN}$$\n","\n","**Quando usar esta m√©trica?**\n","\n","Quando h√° um n√∫mero aproximado de amostras pertencentes a cada classe.\n","\n","**Quando n√£o usar?**\n","\n","Quando apenas uma classe det√©m a maioria das amostras.\n","\n","**Exemplo:** considere que h√° 98% de amostras da classe A e 2% das amostras da classe B em nosso conjunto de treinamento. Ent√£o nosso modelo pode facilmente obter 98% de precis√£o de treinamento simplesmente prevendo cada amostra de treinamento pertencente √† classe A.\n","\n","Quando o mesmo modelo √© testado em um conjunto de teste com 60% de amostras de classe A e 40% de amostras de classe B, a precis√£o do teste cairia para 60%. A precis√£o da classifica√ß√£o pode nos dar a falsa sensa√ß√£o de alcan√ßar alta precis√£o."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IjQxjCAI5ndB"},"outputs":[],"source":["# calculate accuracy\n","\n","acc_logreg = cross_val_score(clf_logreg, X_train, y_train, cv = cv, scoring = 'accuracy').mean()\n","acc_SGD = cross_val_score(clf_SGD, X_train, y_train, cv = cv, scoring = 'accuracy').mean()\n","acc_rfc = cross_val_score(clf_rfc, X_train, y_train, cv = cv, scoring = 'accuracy').mean()\n","\n","acc_logreg, acc_SGD, acc_rfc"]},{"cell_type":"markdown","metadata":{"id":"8Y1FJKzQ5ndC"},"source":["#### **Logarithmic Loss / Log Loss / Logistic Loss / Cross-Entropy Loss** (perda logar√≠tmica)\n","\n","- Ao trabalhar com Log Loss, o classificador deve atribuir probabilidade a cada classe para todas as amostras.\n","- Log loss mede a INCERTEZA das probabilidades do modelo comparando-as com os r√≥tulos verdadeiros e penalizando as classifica√ß√µes falsas.\n","- A perda de log √© definida apenas para dois ou mais r√≥tulos.\n","- Log Loss diminui gradualmente √† medida que a probabilidade prevista melhora, portanto Log Loss mais pr√≥ximo de 0 indica maior precis√£o, Log Loss longe de 0 indica menor precis√£o.\n","- Log Loss existe na faixa (0, ‚àû].\n","\n","Suponha que existam N amostras pertencentes a M classes, ent√£o o Log Loss √© calculado como abaixo:\n","\n","$$ Log\\ Loss = \\frac{-1}{N} \\sum_{i=1}^{N} \\sum_{i=1}^{M}  y_{ij} * \\log(\\hat{y_{ij}})$$\n","\n","Onde,\n","\n","- $y_{ij}$, indica se a amostra i pertence √† classe j ou n√£o\n","\n","- $p_{ij}$, indica a probabilidade da amostra i pertencer √† classe j\n","\n","\n","O sinal negativo nega a sa√≠da $\\log(\\hat{y_{ij}})$ que √© sempre negativa. $\\hat{y_{ij}}$ gera uma probabilidade (0 - 1), $\\log(x)$ √© negativo se 0 < x < 1.\n","\n","<b>Exemplo </b>: deixe que os r√≥tulos de treinamento sejam 0 e 1, mas nossas previs√µes de treinamento sejam 0,4, 0,6, 0,89 etc. Para calcular uma medida do erro do nosso modelo, podemos classificar todas as observa√ß√µes com valores > 0,5 em 1 .Mas, ao faz√™-lo, corremos um alto risco de aumentar a classifica√ß√£o incorreta. Isso ocorre porque pode acontecer que muitos valores com probabilidades 0,4, 0,45, 0,49 possam ter um valor verdadeiro de 1.\n","\n","√â aqui que o logLoss entra em cena.\n","\n","Agora vamos seguir de perto a f√≥rmula de LogLoss. Pode haver 4 casos principais para os valores de $y_{ij}$ e $p_{ij}$\n","\n","- Caso 1: $y_{ij}$=1, $p_{ij}$ = Alto\n","\n","- Caso 2: $y_{ij}$=1, $p_{ij}$ = Baixo\n","\n","- Caso 3: $y_{ij}$=0, $p_{ij}$ = Baixo\n","\n","- Caso 4: $y_{ij}$=0, $p_{ij}$ = Alto\n","\n","**Como o LogLoss mede a incerteza?**\n","\n","Se tivermos mais Caso 1 e Caso 3, ent√£o a soma (e m√©dia) dentro da f√≥rmula de logloss seria maior e seria substancialmente maior em compara√ß√£o com o que teria sido se o Caso 2 e o Caso 4 fossem adicionados. Agora esse valor √© o maior poss√≠vel do Caso 1 e do Caso 3, o que indica uma boa previs√£o. Se o multiplicarmos por (-1) , tornaremos o valor o menor poss√≠vel. Isso agora significaria intuitivamente - Quanto menor o valor, melhor √© o modelo, ou seja, menor o logloss, melhor √© o modelo, ou seja, menor a incerteza, melhor √© o modelo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_I5ep0K35ndC"},"outputs":[],"source":["# calculate logloss\n","\n","logloss_logreg = cross_val_score(clf_logreg, X_train, y_train, cv = cv, scoring = 'neg_log_loss').mean()\n","logloss_rfc = cross_val_score(clf_rfc, X_train, y_train, cv = cv, scoring = 'neg_log_loss').mean()\n","\n","# SGDClassifier's hinge loss doesn't support probability estimates.\n","# We can set SGDClassifier as the base estimator in Scikit-learn's CalibratedClassifierCV, which will generate probability estimates.\n","\n","from sklearn.calibration import CalibratedClassifierCV\n","\n","new_clf_SGD = CalibratedClassifierCV(clf_SGD)\n","new_clf_SGD.fit(X_train, y_train)\n","logloss_SGD = cross_val_score(new_clf_SGD, X_train, y_train, cv = cv, scoring = 'neg_log_loss').mean()\n","\n","logloss_logreg, logloss_SGD, logloss_rfc"]},{"cell_type":"markdown","metadata":{"id":"aIbWQtlU5ndD"},"source":["#### **ROC Curve** ou **Curva ROC**\n","\n","ROC pode ser dividido em sensibilidade e especificidade. Escolher o melhor modelo √© uma esp√©cie de equil√≠brio entre prever 1's com precis√£o ou 0's com precis√£o. Em outras palavras, sensibilidade e especificidade.\n","\n","- **True Positive Rate (Sensibilidade/Recall):** A True Positive Rate √© definida como TP/ (FN+TP). True Positive Rate corresponde √† propor√ß√£o de pontos de dados positivos que s√£o corretamente considerados positivos, com rela√ß√£o a todos os pontos de dados positivos.\n","\n","- **Taxa de falsos positivos (Especificidade):** A taxa de falsos positivos √© definida como FP / (FP+TN). Taxa de falsos positivos corresponde √† propor√ß√£o de pontos de dados negativos que s√£o erroneamente considerados positivos, em rela√ß√£o a todos os pontos de dados negativos.\n","\n","Taxa de verdadeiro positivo e taxa de falso positivo t√™m valores no intervalo [0, 1]. Ambos TPR e FPR s√£o calculados em valores de limiar como (0,00, 0,02, 0,04, ‚Ä¶., 1,00) e um gr√°fico √© desenhado."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y9KruBtV5ndD"},"outputs":[],"source":["# IMPORTANTE: primeiro argumento s√£o valores verdadeiros, segundo argumento s√£o probabilidades previstas\n","\n","# passamos y_test e y_pred_prob\n","# n√£o usamos y_pred_class, pois dar√° resultados incorretos sem gerar erro\n","# roc_curve retorna 3 objetos taxa de falso positivo (fpr), taxa de verdadeiro positivo (tpr), limites\n","\n","fpr_logreg, tpr_logreg, thresholds_logreg = metrics.roc_curve(y_train, y_pred_prob_logreg_class1)\n","fpr_rfc, tpr_rfc, thresholds_rfc = metrics.roc_curve(y_train, y_pred_prob_rfc_class1)\n","fpr_SGD, tpr_SGD, thresholds_SGD = metrics.roc_curve(y_train, y_pred_prob_SGD)\n","\n","plt.plot(fpr_logreg, tpr_logreg, label=\"logreg\")\n","plt.plot(fpr_rfc, tpr_rfc, label=\"rfc\")\n","plt.plot(fpr_SGD, tpr_SGD, label=\"SGD\")\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.0])\n","plt.rcParams['font.size'] = 12\n","plt.title('ROC curve')\n","plt.xlabel('False Positive Rate (1 - Specificity)')\n","plt.ylabel('True Positive Rate (Sensitivity)')\n","plt.legend(loc=\"lower right\", fontsize=10)\n","plt.grid(True)"]},{"cell_type":"markdown","metadata":{"id":"TCnsFtt25ndD"},"source":["**Interpretando o gr√°fico ROC**\n","\n","Interpretar o gr√°fico ROC √© muito diferente de um gr√°fico de linha regular. Porque, embora haja um eixo X e um eixo Y, n√£o o lemos como: para um valor X de 0,25, o valor Y √© 0,9.\n","\n","Em vez disso, o que temos aqui √© uma linha que tra√ßa o corte de probabilidade de 1 no canto inferior esquerdo a 0 no canto superior direito.\n","\n","Essa √© uma maneira de analisar como a sensibilidade e a especificidade se comportam para toda a faixa de pontos de corte de probabilidade, ou seja, de 0 a 1.\n","\n","Idealmente, se tivermos um modelo perfeito, todos os eventos ter√£o uma pontua√ß√£o de probabilidade de 1 e todos os n√£o eventos ter√£o uma pontua√ß√£o de 0. Para tal modelo, a √°rea sob o ROC ser√° um perfeito 1.\n","\n","Assim, se tra√ßarmos a curva a partir do canto inferior esquerdo, o valor de corte de probabilidade diminui de 1 para 0. Se tivermos um bom modelo, mais eventos reais devem ser previstos como eventos, resultando em alta sensibilidade e baixo FPR. Nesse caso, a curva subir√° abruptamente cobrindo uma grande √°rea antes de atingir o canto superior direito.\n","\n","Portanto, quanto maior a √°rea sob a curva ROC, melhor √© o modelo.\n","\n","A curva ROC √© a √∫nica m√©trica que mede o desempenho do modelo para diferentes valores de pontos de corte de probabilidade de previs√£o.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ttX5gMxz5ndE"},"outputs":[],"source":["# define uma fun√ß√£o que aceita um limite(threshold) e imprime sensibilidade e especificidade\n","def evaluate_threshold(tpr, fpr,clf_threshold, threshold):\n","    print('Sensitivity:', tpr[clf_threshold > threshold][-1])\n","    print('Specificity:', 1 - fpr[clf_threshold > threshold][-1])"]},{"cell_type":"markdown","source":["### Avalidando diferentes modelos"],"metadata":{"id":"RwmTIFPkfmTN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2iMG662D5ndE"},"outputs":[],"source":["# Logistic Regression - Regress√£o Log√≠stica\n","evaluate_threshold(tpr_logreg, fpr_logreg, thresholds_logreg, 0.2), evaluate_threshold(tpr_logreg, fpr_logreg, thresholds_logreg, 0.8)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s8PiZb2E5ndF"},"outputs":[],"source":["# Random Forest Classifier - √Årvores aleat√≥rias\n","evaluate_threshold(tpr_rfc, fpr_rfc, thresholds_rfc, 0.2), evaluate_threshold(tpr_rfc, fpr_rfc, thresholds_rfc, 0.8)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"svneaMhJ5ndF"},"outputs":[],"source":["# SGD - Stochastic gradient descent\n","evaluate_threshold(tpr_SGD, fpr_SGD, thresholds_SGD, 0.2), evaluate_threshold(tpr_SGD, fpr_SGD, thresholds_SGD, 0.8)"]},{"cell_type":"markdown","metadata":{"id":"D8Rwga9p5ndF"},"source":["#### **AUC**\n","- A interpreta√ß√£o probabil√≠stica da pontua√ß√£o ROC-AUC √© que se escolhermos aleatoriamente um caso positivo e um caso negativo, a probabilidade de que o caso positivo supere o caso negativo de acordo com o classificador √© dada pela AUC. Aqui, a classifica√ß√£o √© determinada de acordo com a ordem dos valores previstos.\n","- A pontua√ß√£o ROC-AUC √© independente do limite estabelecido para classifica√ß√£o, pois considera apenas a classifica√ß√£o de cada previs√£o e n√£o seu valor absoluto. O mesmo n√£o √© verdade para a pontua√ß√£o F1, que precisa de um valor limite em caso de sa√≠da de probabilidades\n","- AUC √© a porcentagem do gr√°fico ROC que est√° abaixo da curva.\n","- A AUC representa a capacidade de um modelo de discriminar entre classes positivas e negativas. Uma √°rea de 1,0 representa um modelo que fez todas as previs√µes perfeitamente. Uma √°rea de 0,5 representa um modelo t√£o bom quanto aleat√≥rio.\n","- AUC √© √∫til mesmo quando h√° alto desequil√≠brio de classe (ao contr√°rio da precis√£o da classifica√ß√£o)\n","- Caso de fraude\n","     - Precis√£o nula quase 99%\n","     - AUC √© √∫til aqui\n","\n","General AUC predictions (predi√ß√µes da curva AUC):\n","- .90-1 = Excellent\n","- .80-.90 = Good\n","- .70-.80 = Fair\n","- .60-.70 = Poor\n","- .50-.60 = Fail\n","\n","AUC ROC considera as probabilidades previstas para determinar o desempenho do modelo. Mas, leva em considera√ß√£o apenas a ordem das probabilidades e, portanto, n√£o leva em considera√ß√£o a capacidade do modelo de prever maior probabilidade para amostras com maior probabilidade de serem positivas (Log Loss).\n","\n","Enquanto a AUC √© calculada com rela√ß√£o √† classifica√ß√£o bin√°ria com um limite de decis√£o vari√°vel, a perda de log na verdade leva em considera√ß√£o a ‚Äúcerteza‚Äù da classifica√ß√£o."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jNA9mMVL5ndG"},"outputs":[],"source":["roc_auc_logreg = cross_val_score(clf_logreg, X_train, y_train, cv = cv, scoring = 'roc_auc').mean()\n","roc_auc_SGD = cross_val_score(clf_SGD, X_train, y_train, cv = cv, scoring = 'roc_auc').mean()\n","roc_auc_rfc = cross_val_score(clf_rfc, X_train, y_train, cv = cv, scoring = 'roc_auc').mean()\n","\n","roc_auc_logreg, roc_auc_SGD, roc_auc_rfc"]},{"cell_type":"markdown","metadata":{"id":"Yj_YmhWj5ndH"},"source":["####  **Confusion Matrix** ou **Matriz de Confus√£o**\n","\n","Uma matriz de confus√£o √© uma matriz N X N, onde N √© o n√∫mero de classes que est√£o sendo previstas. A Matriz de Confus√£o nos d√° uma matriz como sa√≠da e descreve o desempenho completo do modelo.\n","\n","As previs√µes corretas caem na linha diagonal da matriz.\n","\n","4 termos importantes na Matriz de Confus√£o:\n","- Verdadeiros Positivos: Os casos em que previmos SIM e a sa√≠da real tamb√©m foi SIM.\n","- Verdadeiros Negativos: Os casos em que previmos N√ÉO e a sa√≠da real foi N√ÉO.\n","- Falsos Positivos: Os casos em que previmos SIM e a sa√≠da real foi N√ÉO.\n","- Falsos Negativos: Os casos em que previmos N√ÉO e a sa√≠da real foi SIM.\n","\n","A matriz Confusion em si n√£o √© uma medida de desempenho como tal, mas quase todas as m√©tricas de desempenho s√£o baseadas na Matriz Confusion e nos n√∫meros dentro dela."]},{"cell_type":"markdown","source":["### Avaliando os diferentes modelos"],"metadata":{"id":"8BDyQZHDgHsY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"wA9t8Xac5ndH"},"outputs":[],"source":["logreg_matrix = metrics.confusion_matrix(y_train, y_pred_class_logreg)\n","print(logreg_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xF0OnpPo5ndI"},"outputs":[],"source":["SGD_matrix = metrics.confusion_matrix(y_train, y_pred_class_SGD)\n","print(SGD_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V_kAqG8k5ndI"},"outputs":[],"source":["rfc_matrix = metrics.confusion_matrix(y_train, y_pred_class_rfc)\n","print(rfc_matrix)"]},{"cell_type":"markdown","metadata":{"id":"qhhRMv605ndI"},"source":["####  Classification Report\n","\n","A fun√ß√£o `class_report()` exibe a precis√£o, recall, f1-score e suporte para cada classe.\n","\n","**Precision**\n","\n","√â o n√∫mero de Verdadeiros Positivos dividido pelo n√∫mero de resultados positivos previstos pelo classificador.\n","\n","$$ Precision =  \\frac{True\\ Positives}{True\\ Positives + False\\ Positives} $$\n","\n","![Screen%20Shot%202019-10-17%20at%2009.10.10.png](attachment:Screen%20Shot%202019-10-17%20at%2009.10.10.png)\n","\n","**Recall/ Sensitivity**\n","\n","√â o n√∫mero de Verdadeiros Positivos dividido pelo n√∫mero de todas as amostras relevantes (todas as amostras que deveriam ter sido identificadas como positivas).\n","\n","$$Recall =  \\frac{True\\ Positives}{True\\ Positives + False\\ Negatives}$$\n","\n","![Screen%20Shot%202019-10-17%20at%2009.10.38.png](attachment:Screen%20Shot%202019-10-17%20at%2009.10.38.png)\n","\n","- Para minimizar falsos negativos, gostar√≠amos que nosso Recall fosse o mais pr√≥ximo de 100%\n","- Para minimizar falsos positivos, queremos que nossa precis√£o seja o mais pr√≥ximo de 100%\n","\n","#### <u> Specificity / TNR (True Negative Rate)</u>\n","\n","- Propor√ß√£o de casos negativos reais corretamente identificados.\n","- Especificidade √© exatamente o oposto de Recall.\n","\n","$$Specificity =  \\frac{True\\ Negatives}{True\\ Negatives + False\\ Positives}$$\n","\n","![Screen%20Shot%202019-10-17%20at%2009.11.10.png](attachment:Screen%20Shot%202019-10-17%20at%2009.11.10.png)\n","\n","**F1 Score**\n","\n","- F1 Score √© a m√©dia harm√¥nica entre precis√£o e recall.\n","\n","- Diz qu√£o preciso √© o classificador (quantas inst√¢ncias ele classifica corretamente), bem como qu√£o robusto ele √© (n√£o perde um n√∫mero significativo de inst√¢ncias).\n","- Quanto maior o F1 Score, melhor √© o desempenho do nosso modelo.\n","- Faixa [0, 1].\n","\n","$$F1 = 2 * \\frac{1}{\\frac{1}{precision} + \\frac{1}{recall}}$$\n","\n","**Why Harmonic Mean?**\n","\n","Ex: Temos um modelo de classifica√ß√£o bin√°ria com os seguintes resultados:\n","\n","Precis√£o: 0, Recall: 1\n","\n","Se tomarmos a m√©dia aritm√©tica, obtemos 0,5. √â claro que o resultado acima vem de um classificador burro que apenas ignora a entrada e apenas prev√™ uma das classes como sa√≠da. Agora, se tomarmos HM, obteremos 0, o que √© preciso, pois esse modelo √© in√∫til para todos os fins.\n","\n","A m√©dia harm√¥nica √© uma m√©dia quando x e y s√£o iguais. Mas quando x e y s√£o diferentes, ent√£o est√° mais pr√≥ximo do n√∫mero menor em compara√ß√£o com o n√∫mero maior. Se um n√∫mero for muito pequeno entre precis√£o e recupera√ß√£o, o F1 Score de levanta uma bandeira e est√° mais pr√≥ximo do n√∫mero menor do que do maior, dando ao modelo uma pontua√ß√£o apropriada em vez de apenas uma m√©dia aritm√©tica."]},{"cell_type":"markdown","source":["### Analisando o Log Report"],"metadata":{"id":"blVL-73XgQvz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pQjI6GEH5ndJ"},"outputs":[],"source":["report_logreg = metrics.classification_report(y_train, y_pred_class_logreg)\n","report_SGD = metrics.classification_report(y_train, y_pred_class_SGD)\n","report_rfc = metrics.classification_report(y_train, y_pred_class_rfc)\n","print(\"report_logreg \" +  \"\\n\" + report_logreg,\"report_SGD \"  +  \"\\n\" +  report_SGD,\"report_rfc \"  +  \"\\n\" +  report_rfc, sep = \"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"KGQc86pv5ndJ"},"source":["**Precision: Recall Tradeoff**\n","\n","Em alguns contextos nos preocupamos principalmente com a precis√£o e em outros contextos nos preocupamos com a recorda√ß√£o. Por exemplo, se treinarmos um classificador para detectar v√≠deos seguros para crian√ßas, ew provavelmente preferiria um classificador que rejeitasse muitos v√≠deos bons (baixo recall), mas mantenha apenas os seguros (alta precis√£o). Por outro lado, suponha que treinamos um classificador para detectar ladr√µes de lojas em imagens de vigil√¢ncia: provavelmente n√£o h√° problema se nosso classificador tiver apenas 30% de precis√£o, desde que tenha 99% de recall (com certeza, os guardas de seguran√ßa receber√£o alguns alertas falsos, mas quase todos os ladr√µes ser√£o pegos).\n","\n","Aumentar a Precis√£o reduz o Recall e vice-versa. Isso √© chamado de <i> Precis√£o - Troca de Recall </i>.\n","\n","Para entender essa compensa√ß√£o, vamos ver como o SGDClassifier / LogisticRegression / RandomForestClassifier toma suas decis√µes de classifica√ß√£o. Para cada inst√¢ncia, eles computam uma pontua√ß√£o com base em uma fun√ß√£o de decis√£o /predict_proba e, se essa pontua√ß√£o for maior que um limite, eles atribuem a inst√¢ncia √† classe positiva, ou ent√£o a atribui √† classe negativa."]},{"cell_type":"markdown","metadata":{"id":"Ub7tRClh5ndK"},"source":["Scikit-Learn does not let us set the threshold directly, but it does give us access to the decision scores that it uses to make predictions. Instead of calling the classifier‚Äôs predict() method, we can call its decision_function() method, which returns a score for each instance, and then make predictions based on those scores using any threshold we want:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZMn5lDQ75ndK"},"outputs":[],"source":["y_decision_function_scores = clf_logreg.decision_function(X_train)\n","y_decision_function_scores[6]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LBO_k-TG5ndK"},"outputs":[],"source":["threshold = 0\n","y_decision_function_pred = (y_decision_function_scores[6] > threshold)\n","y_decision_function_pred"]},{"cell_type":"markdown","metadata":{"id":"QC26DP995ndK"},"source":["O classificador usa um limite(threshold) igual a 0, portanto, o c√≥digo anterior retorna o mesmo resultado que o m√©todo predict() (ou seja, True). Vamos aumentar o limite para 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XmEqH5H95ndL"},"outputs":[],"source":["threshold = 2\n","y_decision_function_pred = (y_decision_function_scores[6] > threshold)\n","y_decision_function_pred"]},{"cell_type":"markdown","metadata":{"id":"YlJN0sz-5ndL"},"source":["Isso confirma que aumentar o limite (thresold) diminui o recall.\n","\n","A inst√¢ncia na verdade representa um 1(True) e o classificador o detecta quando o limite √© 0, mas o perde quando o limite √© aumentado para 2.\n","\n","Para decidir qual limite usar, primeiro precisamos obter as pontua√ß√µes de todas as inst√¢ncias no conjunto de treinamento usando a fun√ß√£o cross_val_predict() novamente, mas desta vez especificando que voc√™ deseja que ela retorne pontua√ß√µes/probabilidades de decis√£o em vez de classe:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f0zMwKhQ5ndL"},"outputs":[],"source":["from sklearn.metrics import precision_recall_curve\n","\n","precisions, recalls, thresholds = precision_recall_curve(y_train, y_pred_prob_logreg_class1)\n","\n","def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n","    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n","    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n","    plt.xlabel(\"Threshold\")\n","    plt.legend(loc=\"upper left\")\n","    plt.ylim([0, 1])\n","\n","plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"02cDImzA5ndM"},"source":["Agora podemos simplesmente selecionar o valor limite que nos d√° a melhor compensa√ß√£o de precis√£o/recall para nossa tarefa. vamos supor que voc√™ decida buscar 80% de recall.\n","\n","Olhamos o primeiro gr√°fico ou \"plot\" (aumentando um pouco) e descobrimos que precisamos usar um limite de cerca de 0,32.\n","\n","Para fazer previs√µes (no conjunto de treinamento por enquanto), em vez de chamar o m√©todo predict() do classificador, voc√™ pode simplesmente executar este c√≥digo:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QaG-PQgN5ndM"},"outputs":[],"source":["from sklearn.metrics import precision_score, recall_score\n","\n","y_pred_90 = (y_pred_prob_logreg_class1 > 0.32)\n","\n","precisionScore = precision_score(y_train, y_pred_90)\n","recallScore = recall_score(y_train, y_pred_90)\n","precisionScore, recallScore"]},{"cell_type":"markdown","metadata":{"id":"P_aBqdJm5ndM"},"source":["#### **Conclus√£o**\n","\n","##### **Compara√ß√£o de Log-loss com ROC & F1**\n","\n","**Caso 1: Conjunto de dados balanceado**\n","\n","| S.No. | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 |\n","| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n","| Actual (Balanced) | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 |\n","| Predicted (Model 1) | 0.1 | 0.1 | 0.1 | 0.1 | 0.1 | 0.1 | 0.6 | 0.6 | 0.5 | 0.5 | 0.9 | 0.9 | 0.9 | 0.9 | 0.9 | 0.9 |\n","| Predicted (Model 1) | 0.6 | 0.6 | 0.6 | 0.6 | 0.6 | 0.6 | 0.6 | 0.6 | 0.7 | 0.7 | 0.7 | 0.7 | 0.8 | 0.8 | 0.8 | 0.8 |\n","\n","Considere o caso 1 (dados balanceados), parece que o modelo 1 est√° fazendo um trabalho melhor na previs√£o das probabilidades absolutas, enquanto o modelo 2 est√° funcionando melhor na classifica√ß√£o das observa√ß√µes de acordo com seus r√≥tulos verdadeiros. Vamos verificar com a pontua√ß√£o real:\n","\n","| F1 (threshold = 0.5) | F1 (threshold which maximize score) | ROC - AUC | LogLoss |\n","| --- | --- | --- | --- |\n","| Model 1 | 0.88 | .88 | 0.94 | 0.28\n","| Model 2 | 0.67 | 1 | 1 | 0.6\n","\n","Se considerarmos o log loss, o Modelo 2 √© o pior, dando um alto valor de perda de log porque as probabilidades absolutas t√™m grande diferen√ßa dos r√≥tulos reais. Mas isso est√° em total desacordo com a pontua√ß√£o F1 e AUC, segundo a qual o Modelo 2 tem 100% de precis√£o. Al√©m disso, gostar√≠amos de observar que, com diferentes limites, a pontua√ß√£o F1 est√° mudando e preferindo o modelo 1 ao modelo 2 para o limite padr√£o de 0,5.\n","\n","<b> Infer√™ncias extra√≠das do exemplo acima (conjunto de dados balanceado) </b>:\n","- Se nos importamos com a diferen√ßa probabil√≠stica absoluta, vamos com Log Loss\n","- Se nos importamos apenas com a previs√£o da classe final e n√£o queremos ajustar o limite, v√° com a pontua√ß√£o AUC.\n","-A pontua√ß√£o F1 √© sens√≠vel ao limiar e gostar√≠amos de ajust√°-la primeiro antes de comparar os modelos.\n","\n","##### **Caso 2: Conjunto de dados desbalanceado**\n","\n","**A) Desbalanceado - Poucos Positivos**\n","\n","| S.No. | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 |\n","| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n","| Actual (Balanced) | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 |\n","| Predicted (Model 1) | 0.1 | 0.1 | 0.1 | 0.1 | 0.1 | 0.1 | 0.1 | 0.1 | 0.1 | 0.1 | 0.1 | 0.1 | 0.1 | 0.1 | 0.9 | 0.9 |\n","| Predicted (Model 1) | 0.1 | 0.1 | 0.1 | 0.1 | 0.1 | 0.1 | 0.1 | 0.1 | 0.1 | 0.1 | 0.1 | 0.1 | 0.9 | 0.9 | 0.9 | 0.9 |\n","\n","| | F1 (threshold = 0.5) | ROC - AUC | LogLoss |\n","| --- | --- | --- | --- |\n","| Model 1 | 0.8 | .83 | .24\n","| Model 2 | 0.86 | .96 | .24\n","\n","A √∫nica diferen√ßa no modelo1 e no modelo2 √© sua previs√£o para a observa√ß√£o 13 e 14. O modelo 1 est√° fazendo um trabalho melhor na classifica√ß√£o da observa√ß√£o 13 (r√≥tulo 0), enquanto o modelo 2 est√° se saindo melhor na classifica√ß√£o da observa√ß√£o 14 (r√≥tulo 1). O objetivo √© ver qual modelo realmente captura melhor a diferen√ßa na classifica√ß√£o da classe desequilibrada (classe com poucas observa√ß√µes, aqui est√° o r√≥tulo 1). Em problemas como detec√ß√£o de fraude/detec√ß√£o de spam, onde os r√≥tulos positivos s√£o poucos, gostar√≠amos que nosso modelo predissesse classes positivas corretamente e, portanto, √†s vezes preferimos aqueles modelos que s√£o capazes de classificar esses r√≥tulos positivos.\n","\n","Claramente, a perda de log est√° falhando neste caso porque, de acordo com a perda de log, ambos os modelos est√£o funcionando igualmente. Isso ocorre porque a fun√ß√£o log-loss √© sim√©trica e n√£o diferencia entre classes.\n","\n","Tanto a pontua√ß√£o F1 quanto a pontua√ß√£o ROC-AUC est√£o se saindo melhor ao preferir o modelo 2 ao modelo 1. Portanto, podemos usar esses dois m√©todos para desequil√≠brio de classe.\n","\n","**B) Desbalanceado - Poucos Negativos**\n","\n","| S.No. | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 |\n","|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n","| Actual (Balanced) | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 |\n","| Predicted (Model 1) | 0.1 | 0.1 | 0.9 | 0.9 | 0.9 | 0.9 | 0.9 | 0.9 | 0.9 | 0.9 | 0.9 | 0.9 | 0.9 | 0.9 | 0.9 | 0.9 |\n","| Predicted (Model 1) | 0.1 | 0.1 | 0.1 | 0.1 | 0.9 | 0.9 | 0.9 | 0.9 | 0.9 | 0.9 | 0.9 | 0.9 | 0.9 | 0.9 | 0.9 | 0.9 |\n","\n","|| F1 (threshold = 0.5) | ROC - AUC | LogLoss |\n","| --- | --- | --- | --- |\n","| Model 1 | 0.963 | .83 | .24\n","| Model 2 | 0.96 | .96 | .24\n","\n","A pontua√ß√£o ROC-AUC tratou o caso de poucos r√≥tulos negativos da mesma forma que tratou o caso de poucos r√≥tulos positivos. A pontua√ß√£o F1 √© praticamente a mesma para o Modelo 1 e o Modelo 2 porque os r√≥tulos positivos s√£o grandes em n√∫mero e se preocupa apenas com a classifica√ß√£o incorreta dos r√≥tulos positivos.\n","\n","##### **Infer√™ncias extra√≠das do exemplo acima (conjunto de dados desequilibrado)**\n","\n","- Se cuidarmos de uma classe que √© menor em n√∫mero independente do fato de ser positiva ou negativa, v√° para a pontua√ß√£o ROC-AUC.\n","\n","##### **Quando vamos preferir F1 sobre ROC-AUC?**\n","\n","Prefira a curva PR sempre que a classe positiva for rara ou quando nos preocuparmos mais com os falsos positivos do que com os falsos negativos.\n","\n","Para treinar classificadores bin√°rios, escolha a m√©trica apropriada para a tarefa, avalie os classificadores usando valida√ß√£o cruzada, selecione a compensa√ß√£o de precis√£o/recupera√ß√£o que atenda √†s nossas necessidades e compare v√°rios modelos usando curvas ROC e pontua√ß√µes ROC AUC."]},{"cell_type":"markdown","metadata":{"id":"cw5HBGcU5ndN"},"source":["### **M√©tricas de Regress√£o**\n","\n","Usaremos o dataset [housing.csv](https://drive.google.com/file/d/1jAhlBKt-dKz3kwt2Xav1WuWg58gKWxB-/view?usp=share_link) para esta pr√°tica."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wjlf59Ry5ndN"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn import metrics\n","import matplotlib.pyplot as plt\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","housing_data = pd.read_csv('/content/drive/MyDrive/housing.csv')\n","housing_data.head()"]},{"cell_type":"code","source":["X =  housing_data.drop([\"MEDV\"],axis = 1)\n","y = housing_data[\"MEDV\"]\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n","\n","model = LinearRegression()\n","\n","# fit model\n","model.fit(X_train, y_train)\n","\n","# make class predictions for the testing set\n","y_pred_class = model.predict(X_test)"],"metadata":{"id":"l4UQY6uyHMjG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wKo7etJT5ndN"},"source":["#### **MAE - Mean Absolute Error** ou  **Erro m√©dio absoluto**\n","- M√©dia da diferen√ßa entre os Valores Originais e os Valores Previstos.\n","- N√£o d√° nenhuma ideia da dire√ß√£o do erro, ou seja, se estamos prevendo os dados ou superestimando os dados.\n","- Quanto menor o MAE, melhor √© o modelo.\n","- Robusto para outliers\n","- Alcance (0, + infinito]\n","\n","$$ Mean\\ Absolute\\ Error = \\frac{1}{N} \\sum_{i=1}^{N} |y_{i} -  \\hat{y_{i}}|$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QgTc8LFe5ndN"},"outputs":[],"source":["# calculate Mean Absolute Error\n","\n","print(metrics.mean_absolute_error(y_test, y_pred_class))"]},{"cell_type":"markdown","metadata":{"id":"mh2V1f7h5ndO"},"source":["#### **MSE - Mean Squared Error** ou **Erro M√©dio Quadr√°tico**\n","\n","- Tira a m√©dia do quadrado da diferen√ßa entre os valores originais e os valores previstos.\n","- √Ä medida que tomamos o quadrado do erro, o efeito de erros maiores (√†s vezes discrepantes) torna-se mais pronunciado do que o erro menor. O modelo ser√° mais penalizado por fazer previs√µes que diferem muito do valor real correspondente.\n","- Antes de aplicar o MSE, devemos eliminar todos os nulos/infinitos da entrada.\n","- N√£o √© robusto a outliers\n","- Alcance (0, + infinito]\n","\n","$$ Mean\\ Squared\\ Error = \\frac{1}{N} \\sum_{i=1}^{N} (y_{i} -  \\hat{y_{i}})^2$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L1clgOW95ndO"},"outputs":[],"source":["# calculo do Mean Squared Error\n","print(metrics.mean_squared_error(y_test, y_pred_class))"]},{"cell_type":"markdown","metadata":{"id":"Zdme7FIW5ndO"},"source":["#### **MAE vs. MSE**\n","- Sendo mais complexo e tendencioso para um desvio mais alto, o RMSE ainda √© a m√©trica padr√£o de muitos modelos porque a fun√ß√£o de perda definida em termos de RMSE √© suavemente diferenci√°vel, enquanto o MAE (Erro Absoluto M√©dio) requer programa√ß√£o linear complicada para calcular o gradiente.\n","- Se queremos uma m√©trica apenas para comparar dois modelos do ponto de vista de interpreta√ß√£o, ent√£o o MAE pode ser uma escolha melhor.\n","- As unidades de RMSE e MAE s√£o iguais aos valores de y, o que n√£o √© verdade para R Square.\n","- Minimizar o erro quadrado (ùêø2) sobre um conjunto de n√∫meros resulta em encontrar sua m√©dia, e minimizar o erro absoluto (ùêø1) resulta em encontrar sua mediana."]},{"cell_type":"markdown","metadata":{"id":"RGZwZQ7h5ndO"},"source":["#### **RMSE**\n","\n","- Como o MSE √© quadr√°tico, suas unidades n√£o correspondem √†s da sa√≠da original. RMSE √© a raiz quadrada de MSE.\n","- Uma vez que o MSE e o RMSE ambos quadram o res√≠duo, eles s√£o afetados da mesma forma por valores discrepantes.\n","- O RMSE √© an√°logo ao desvio padr√£o e √© uma medida do tamanho dos res√≠duos espalhados.\n","- - Geralmente, o RMSE ser√° maior ou igual ao MAE.\n","\n","$$ Root\\ Mean\\ Squared\\ Error =\\sqrt{ \\frac{1}{N} \\sum_{i=1}^{N} (y_{i} -  \\hat{y_{i}})^2}$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pFCCMc4U5ndO"},"outputs":[],"source":["# calculate Root Mean Squared Error\n","\n","from math import sqrt\n","\n","print(sqrt(metrics.mean_squared_error(y_test, y_pred_class)))"]},{"cell_type":"markdown","metadata":{"id":"GiGnd-eO5ndP"},"source":["#### **RMSLE - Root Mean Squared Logarithmic Error**\n","- Tomamos o log das previs√µes e valores reais.\n","- Quais mudan√ßas s√£o a vari√¢ncia que estamos medindo.\n","- O RMSLE geralmente √© usado quando n√£o queremos penalizar grandes diferen√ßas nos valores previstos e reais quando os valores previstos e reais s√£o n√∫meros enormes.\n","- Se os valores previstos e reais forem pequenos: RMSE e RMSLE s√£o iguais.\n","- Se o valor previsto ou real for grande: RMSE > RMSLE\n","- Se os valores previstos e reais forem grandes: RMSE > RMSLE (RMSLE torna-se quase insignificante)\n","\n","$$ Root\\ Mean\\ Squared\\ Log\\ Error =\\sqrt{ \\frac{1}{N} \\sum_{i=1}^{N} (\\log (y_{i} + 1) -  (\\log \\hat{y_{i}} + 1))^2}$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o9KNfl9-5ndP"},"outputs":[],"source":["# calculate Mean Squared Log Error\n","\n","print(metrics.mean_squared_log_error(y_test, y_pred_class))"]},{"cell_type":"markdown","metadata":{"id":"9Osbsyei5ndP"},"source":["#### **R-squared**\n","\n","No caso de um problema de classifica√ß√£o, se o modelo tiver uma precis√£o de 0,8, podemos avaliar o qu√£o bom nosso modelo √© em rela√ß√£o a um modelo aleat√≥rio, que tem uma precis√£o de 0,5. Assim, o modelo aleat√≥rio pode ser tratado como um benchmark. Mas quando falamos em m√©tricas de RMSE, n√£o temos um benchmark para comparar.\n","\n","√â aqui que podemos usar a m√©trica R-squared. A f√≥rmula para R-squared √© a seguinte:\n","\n","$$R^2 = 1 - \\frac{MSE(model)}{MSE(baseline)} = 1 - \\frac{\\sum_{i=1}^{N}(y_1 - \\hat{y_1})^2}{\\sum_{i=1}^{N}(\\bar{y_1} - \\hat{y_1})^2}$$\n","\n","MSE(model): Mean Squared Error of the predictions against the actual values\n","\n","MSE(baseline): Mean Squared Error of  mean prediction against the actual values\n","\n","In other words how good our regression model as compared to a very simple model that just predicts the mean value of target from the train set as predictions.\n","- A model performing equal to baseline would give R-Squared as 0. Better the model, higher the r2 value.\n","- Range[- infinity, 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2VqTymwd5ndQ"},"outputs":[],"source":["# calculate R2 score\n","\n","print(metrics.r2_score(y_test, y_pred_class))"]},{"cell_type":"markdown","metadata":{"id":"3BU3mF025ndQ"},"source":["#### **Adjusted R-Squared**\n","\n","Ao adicionar novos recursos ao modelo, o valor R-Squared aumenta ou permanece o mesmo. O R-Squared n√£o penaliza a adi√ß√£o de recursos que n√£o agregam valor ao modelo. Portanto, uma vers√£o melhorada sobre o R-Squared √© o R-Squared ajustado. A f√≥rmula para R-Quadr√°tico ajustado √© dada por:\n","\n","$$\\bar{R^2} = 1 - (1 - R^2)(\\frac{n - 1}{n - k + 1})$$\n","\n","- k: number of features - n√∫mero de features\n","- n: number of samples - n√∫mero de exemplos\n","\n","Essa m√©trica leva em considera√ß√£o o n√∫mero de recursos. Quando adicionamos mais recursos, o termo no denominador n-(k +1) diminui, ent√£o toda a express√£o aumenta."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RpaAOH2Z5ndQ"},"outputs":[],"source":["import statsmodels.api as sm\n","\n","X_train_2 = sm.add_constant(X_train)\n","est = sm.OLS(y_train, X_train_2)\n","est2 = est.fit()\n","\n","print(\"summary()\\n\",est2.summary())"]},{"cell_type":"markdown","source":["---\n","\n","Notebook utilizado para fins educacionais da **Awari**.\n","\n","**¬© AWARI. Todos os direitos reservados.**"],"metadata":{"id":"PEUwtERx9ALH"}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"provenance":[{"file_id":"1pFk5XwxlFcnqyGWkengZu-JPYJBSOXbe","timestamp":1727314180172}],"collapsed_sections":["nXkxaYu75ndB","8Y1FJKzQ5ndC","P_aBqdJm5ndM","wKo7etJT5ndN","Zdme7FIW5ndO","RGZwZQ7h5ndO","GiGnd-eO5ndP","9Osbsyei5ndP"]}},"nbformat":4,"nbformat_minor":0}